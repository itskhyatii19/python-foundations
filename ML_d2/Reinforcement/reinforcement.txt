q1.What does count_frequency do?
=>the defined function count_frequency creates a dictionry consisting all the numbers provided in their list along with their frequencies i.e. the no. of times these numbers were repeated in the list.It creates a dictionary where keys are items from the list and values are the number of times each item appears.

q2.Why is if item in freq needed?
=>freq[item] += 1 ONLY works if freq[item] already exists.
If it doesn’t exist, Python throws a KeyError
So the if check is needed to decide whether to increment an existing count or initialize it to 1

q3.What would break if that if was removed?
=>On the first occurrence of any item
Python tries: freq[item] += 1
But freq[item] does not exist yet so python raises a KeyError.
Program crashes immediately and no frequencies are calculated at all.

q4.One mistake you might make if writing it again
=>getting confused between freq[item] or item[freq]

q5.def add(a,b):
     return a+b
_____________________
Q1 What are features (X)?
=> Features (X) are the input variables (columns) that the model uses to make predictions.
Q2 What is the target (y)?
=>Target (y) is the output variable (column) that we want the model to predict. 
Q3 Why do we split data into train and test?
=> We split data so that the model is evaluated on unseen data, which helps us measure how well it generalizes, not just how well it memorizes. the ratio of train:test is usually 80:20 or 70:30
Q4 What could go wrong if we train and test on the same data? 
=>The model may overfit — it appears to perform well on training data but fails on unseen data.

_____________________
Q1. What is underfitting?
=>this happens when the model underperforms on the training data due to high variance and high bias
Q2. What is overfitting?
=>this happens when the model overperforms in training data due to low bias(little to no error in training data) hand high variance
Q3. Where does linear regression usually fail?
=>linear regression fails when the relationship between the features and target is not linear
Q4. Why can a complex model perform worse on test data?
=>a complex model can perform worse on test data if the mdel has high variance and low bias i.e if the model is overfitted

_____________________
Q1. What problem did linear regression solve?
=>Linear regression solved the problem of memorisation by bringing the concept of generalization.It solves the problem of predicting a continuous value by learning a general relationship between input and output instead of memorizing data points.
Q2. Why did polynomial regression overfit?
=>polynomial regression overfitted when the degree was taken too high which resulted in the formed curve trying to touch almost all data points.the model became too complex for the small dataset, causing it to learn noise instead of true patterns.
Q3. What does random_state actually control?
=>random_state actually controls the randomness in how the test-test split happens every time to ensure code reproducibility and reusability.same train_test_split every time means same input and output elements and same result.helpful for debugging
Q4. One mistake beginners make in ML.
=>trying to get 100% accurary thinking it improves the model performancewhen it actually causes overfitting

_____________________
Q1. What is the difference between:
pd.read_csv("file.csv")
pd.read_csv("file.csv", usecols=["col1","col2"])
Why would you prefer the second one?
 =>the first one reads all columns from the CSV file whereas the second one Reads only specified columns (col1, col2)..i would prefer the second one when i wont be needing every column of the dataset and also because it Saves memory, Faster loading, Cleaner dataframe.
Q2. What does this do?
pd.read_csv("data.csv", na_values=["NA", "N/A", "missing"])
Why is it important for data cleaning?
 =>this Converts "NA", "N/A", "missing" into actual NaN values .It is important Because:
Pandas functions (isnull(), fillna(), dropna()) work only on real NaN.
Prevents: Wrong statistics, Model errors, Garbage data.
Q3.Explain what happens when you use:
chunks = pd.read_csv("big.csv", chunksize=5000)
When is this useful in real projects?
 =>this helps us Loads file in batches of 5000 rows and returns an iterator.This is extremely useful in real projects when dataset is very large (GBs) and doesn't fit in memory.
Q4. What is the purpose of:
git commit --amend
When should you not use it?
 =>it is used to modify last commit, Change message, Add/remove files and Rewrites commit history.
 Should not be used if commit is already pushed or Shared with others(only for local commits)
_____________________
Q1. What’s the difference between a Python dict and JSON?
=> Python dictionary: A native Python data structure that exists only inside Python memory. It uses single quotes and can store any Python object.
   JSON: Text-based data format Used for data exchange (APIs, files). It is language independent and uses double quotes.It Can only store basic types (string, number, list, bool, null)
Q2. How do you safely load a JSON file and handle missing keys?
=>we can safely load a Json file by using df.read_json('path'). to handle missing values we can use df.isnull().sum() to first count the missing values and then we can handle them
Q3. Write a function that flattens nested JSON into a flat dict.
=>import pandas as pd
  def flatten_json_pandas(json_data):
    df = pd.json_normalize(json_data)
    return df
Q4. Explain why APIs usually return JSON and how Python’s requests handles it.
=>Most modern APIs return data in JSON format because: Lightweight, Human readable, Language independent, Easy to parse.
import requests
response = requests.get("API_URL")
data = response.json()
Q5. What’s the difference between a SQL JOIN and filtering with WHERE?
=>WHERE is used to:Filter rows inside same table
  JOIN is used to Combine multiple tables based on common column